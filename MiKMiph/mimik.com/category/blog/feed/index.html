<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Blog - mimik Technology Inc</title>
	<atom:link href="https://mimik.com/category/blog/feed/" rel="self" type="application/rss+xml" />
	<link>https://mimik.com</link>
	<description>Your Competitive Edge</description>
	<lastBuildDate>Tue, 30 Jan 2024 20:49:31 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.5.3</generator>

<image>
	<url>https://mimik.com/wp-content/uploads/2023/10/cropped-Favicon-mimik-Favicon-mimik-525 × 525-white-32x32.png</url>
	<title>Blog - mimik Technology Inc</title>
	<link>https://mimik.com</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Bridging Worlds: Hybrid Edge Cloud and Distributed Ledger Reshaping Digital Services &#038; Knowledge Exchange</title>
		<link>https://mimik.com/bridging-worlds-hybrid-edge-cloud-and-distributed-ledger-reshaping-digital-services-knowledge-exchange/</link>
		
		<dc:creator><![CDATA[Siavash Alamouti]]></dc:creator>
		<pubDate>Tue, 09 Jan 2024 14:29:18 +0000</pubDate>
				<category><![CDATA[Blog]]></category>
		<guid isPermaLink="false">https://mimik.com/?p=82485</guid>

					<description><![CDATA[<p>In today’s dynamic digital landscape, the convergence of edge computing and distributed ledger technology unveils a transformative potential that extends far beyond mere technical buzzwords. Beyond the limelight of these innovations, lies the creation of a monumental knowledge-as-a-service economy that could revolutionize the existing multi-trillion-dollar data broker system — an ecosystem riddled with opacity, guesswork, [&#8230;]</p>
<p>The post <a href="https://mimik.com/bridging-worlds-hybrid-edge-cloud-and-distributed-ledger-reshaping-digital-services-knowledge-exchange/">Bridging Worlds: Hybrid Edge Cloud and Distributed Ledger Reshaping Digital Services & Knowledge Exchange</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></description>
										<content:encoded><![CDATA[<p id="9e16">In today’s dynamic digital landscape, the convergence of edge computing and distributed ledger technology unveils a transformative potential that extends far beyond mere technical buzzwords. Beyond the limelight of these innovations, lies the creation of a monumental knowledge-as-a-service economy that could revolutionize the existing multi-trillion-dollar data broker system — an ecosystem riddled with opacity, guesswork, data scraping, and unauthorized information exploitation.</p>



<p id="7c20"><a href="https://ieeexplore.ieee.org/document/9846938" target="_blank" rel="noreferrer noopener">Hybrid Edge Cloud (HEC)</a> pioneered by <a href="https://mimik.com/" target="_blank" rel="noreferrer noopener">mimik</a> is a pivotal player, empowering smart devices to act as cloud servers to locally run workflows, seamlessly share data, knowledge, and computing resources, collaborate via APIs, and transfer microservices among devices, fostering an interconnected digital ecosystem.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img fetchpriority="high" decoding="async" width="1024" height="933" src="https://mimik.com/wp-content/uploads/2024/01/1_7BYc61PxfhqS1sFNoPRj8g-1024x933.webp" alt="" class="wp-image-82486" style="width:601px;height:auto" srcset="https://mimik.com/wp-content/uploads/2024/01/1_7BYc61PxfhqS1sFNoPRj8g-1024x933.webp 1024w, https://mimik.com/wp-content/uploads/2024/01/1_7BYc61PxfhqS1sFNoPRj8g-300x273.webp 300w, https://mimik.com/wp-content/uploads/2024/01/1_7BYc61PxfhqS1sFNoPRj8g-768x700.webp 768w, https://mimik.com/wp-content/uploads/2024/01/1_7BYc61PxfhqS1sFNoPRj8g.webp 1200w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure></div>


<p class="has-text-align-center has-cyan-bluish-gray-color has-text-color has-link-color wp-elements-abef05b9a66aa523df1a9d641f96b522">The mimik HEC platform enabling any smart device to act as a cloud server.</p>



<p id="4a7a">Complementing this, distributed ledger technology, particularly within the realm of private chains and smart contracts tailored for a smaller set of stakeholders, takes charge of managing financial transactions in a secure, transparent, traceable, immutable, and efficient way. It’s crucial to distinguish this approach from the widely publicized crypto hype. Unlike the public blockchains associated with cryptocurrencies, private chains operate within a confined network, ensuring computational efficiency and scalability. These private chains, governed by smart contracts, enforce transparent and predefined rules agreed upon by a smaller set of stakeholders. This computational efficiency is a cornerstone, allowing for streamlined transactions and reducing the computational cost and environmental footprint associated with large-scale public blockchain networks.</p>



<p></p>



<p id="914f">Imagine a world where mimik’s HEC serves as an open arena, allowing services to fluidly run on smart devices and effortlessly discover, collaborate, and exchange knowledge autonomously. Envision a smart thermostat communicating with your wearable to read your body temperature and then dynamically optimize temperature and energy consumption based on the current context. Through this framework, services can be hosted on devices and can collaboratively navigate tasks creating an environment far removed from centralized pre-defined control and guesswork.</p>



<p></p>



<p id="53a6">In this digital milieu, microservices play a pivotal role, akin to specialized functions executed by smart devices — language translation, image processing, or data analysis, for instance. Traditionally, confined to centralized servers in data centers, mimik’s platform revolutionizes this landscape, facilitating the seamless traversal of microservices across devices. For instance, your smartphone can momentarily borrow an image processing microservice from your tablet, enhancing its capabilities instantly. This decentralized sharing of microservices endows devices with dynamic prowess, optimizing their functions collectively.</p>



<p></p>



<p id="8c38">While mimik platform enables choreography of this seamless flow of microservices, private chains and tailored smart contracts within the network ensure secure and efficient transactions with audit trails and logs. Consider an autonomous drone in need of an AI model for fault detection in an industrial site or a port facility. mimik’s platform seamlessly facilitates the drone’s access to this model from another smart device, gateway, or a cloud server through a secure exchange within the private chain. The implementation of smart contracts ensures the integrity and transparency of this exchange, fostering a fair and efficient transaction environment.</p>



<p></p>



<p id="c0f4">Yet, the transformative power of this collaborative ecosystem goes beyond mere technical advancements. It envisions a shift — a monumental departure from the prevailing data broker system — to an automated, traceable knowledge-as-a-service economy. Here, stakeholders are rewarded for contributing accurate, valuable information and collaborating seamlessly. This paradigm disrupts the underhanded practices of the data broker economy, replacing opacity and guesswork with transparency and collaboration, fostering an ecosystem where all stakeholders are fairly rewarded for their contributions.</p>



<p></p>



<p id="da74">In essence, this convergence of HEC and distributed ledger not only elevates the efficiency, security, and autonomy of device collaboration but lays the foundation for a revolutionary knowledge-as-a-service economy — a beacon of fairness, transparency, and collaboration across diverse industries.</p><p>The post <a href="https://mimik.com/bridging-worlds-hybrid-edge-cloud-and-distributed-ledger-reshaping-digital-services-knowledge-exchange/">Bridging Worlds: Hybrid Edge Cloud and Distributed Ledger Reshaping Digital Services & Knowledge Exchange</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>The four stages of edge AI</title>
		<link>https://mimik.com/the-four-stages-of-edge-ai/</link>
		
		<dc:creator><![CDATA[Michel Burger]]></dc:creator>
		<pubDate>Mon, 27 Nov 2023 20:45:36 +0000</pubDate>
				<category><![CDATA[Blog]]></category>
		<guid isPermaLink="false">https://mimik.com/?p=81939</guid>

					<description><![CDATA[<p>In the rapidly evolving world of edge computing and artificial intelligence (AI), there are several crucial stages to consider. This blog delves into the complexities and innovations at each stage, beginning with Local Execution, where AI models are deployed directly on edge devices for real-time data processing. We then explore Contextualization, focusing on the local [&#8230;]</p>
<p>The post <a href="https://mimik.com/the-four-stages-of-edge-ai/">The four stages of edge AI</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>In the rapidly evolving world of edge computing and artificial intelligence (AI), there are several crucial stages to consider. This blog delves into the complexities and innovations at each stage, beginning with Local Execution, where AI models are deployed directly on edge devices for real-time data processing. We then explore Contextualization, focusing on the local handling of contextual information for personalized responses. The third stage, AI to AI Communication, examines the critical coordination between multiple AI nodes, facilitated by edge microservices. Finally, AI-adapted Choreography highlights how multiple AI models across an edge network can dynamically interact with each other, optimizing overall system performance. Through these stages, the role of mimik technology emerges as pivotal, enabling seamless integration and efficient operation of AI models in edge computing environments.</p>



<h3 class="wp-block-heading"><strong>Stage 1: Local Execution</strong></h3>



<p>In this stage, the focus is on deploying the AI model at the edge, which means running the model directly on the device that generates the data. Typically, the model is trained in the cloud and then pushed to the edge devices such as cameras or sensors. The purpose is to perform real-time recognition or analysis of data streams locally without relying on constant communication with the cloud.</p>



<p>The information generated by the local execution can be handled in different ways. If the recognition results are conclusive, only the result is sent to the cloud for further processing or storage. However, if the recognition is inconclusive, the image or relevant data may be sent to the cloud to retrain the model. Additionally, a lower resolution of the data stream can be archived for reference purposes.</p>



<p>For example, consider a security camera system using edge computing. The camera captures live video footage and runs an AI model locally for real-time object detection. Instead of sending every frame to the cloud for analysis, the AI model is deployed directly on the camera. The camera processes the video stream locally, identifies objects of interest, and sends only the relevant information, such as detected objects and their locations, to the cloud for further processing or storage.</p>



<p>It is essential to separate the model from the execution process because models need regular updates and the ability to manage the payload remotely. Mimik enables this separation by treating the model as a part of the edge microservice running on the device. The microservice acts as an interface between the cloud and the AI process, abstracting the handling of model updates from the recognition process. Another edge microservice handles the results, whether sending them to the cloud or other local systems. This ensures that the model can be easily updated and fine-tuned without disrupting the process of recognition or analysis.</p>



<p>By exposing the capabilities of handling the model and results as a local API, mimik simplifies the development process of AI solutions, making integrating edge computing into the workflow easier.</p>



<h3 class="wp-block-heading" id="Stage-2:-Contextualization"><strong>Stage 2: Contextualization</strong></h3>



<p>In this stage, the model is executed locally, and the handling of the context in which the process occurs is also done locally. The context refers to events received by the device running the process or other devices within the same cluster, such as events triggered by user inputs through a UI or sensor inputs.</p>



<p>Local contextualization allows for the personalization of the model based on user preferences or specific scenarios. By processing events locally, edge devices can provide tailored experiences or responses without constantly sending data to the cloud for analysis and decision-making.</p>



<p>For example, consider an intelligent home system using edge computing. The system includes various devices like smart speakers, cameras, and sensors. Each device runs AI models locally to process data and respond to user commands. When a user speaks a command to a smart speaker, the AI model on the speaker processes the command locally, taking into account the context of the user&#8217;s preferences and the current state of the home environment. The speaker can provide personalized responses or control other devices within the cluster based on local contextual information.</p>



<p>Mimik achieves contextualization by running multiple edge microservices on the same node and facilitating interaction with other edge microservices on different nodes. This decentralized approach minimizes the need for data transfer to the cloud, as the devices within the cluster can communicate and share contextual information directly.</p>



<h3 class="wp-block-heading" id="Stage-3:-AI-to-AI-communication">Stage 3: AI to AI communication</h3>



<p>In this stage, there is the realization that a complex system at the edge will be made of many nodes that can have an AI handling the node&#8217;s logic. In this environment, while the execution of the model happens at the edge, the integration between each AI is coordinated via the cloud. It must be possible to allow direct communication between each AI to handle local decision-making by having the different AI either exchange the models or exchange the events generated by the API process using the models.</p>



<p>For example, consider an autonomous driving system using edge computing. The system comprises multiple edge devices, such as cameras, LiDAR sensors, and control units, each running its own AI model for perception, decision-making, and control. These devices must exchange information and coordinate safe and efficient driving decisions. Instead of relying solely on a centralized system in the cloud, direct communication between the edge devices&#8217; AI models is essential for local decision-making.</p>



<p>Mimik enables AI-to-AI communication by allowing models to be handled by edge microservices and creating an ad-hoc edge service mesh. This allows direct communication between edge microservices within the same node or between edge microservices running on different nodes. With mimik, multiple AIs at the edge can exchange information or models with a well-defined contract, facilitating coordinated actions without heavy reliance on a centralized cloud system.</p>



<h3 class="wp-block-heading" id="Stage-4:-AI-adapted-choreography">Stage 4: AI-adapted choreography</h3>



<p>In this stage, the focus is on dynamically choreographing the behavior of multiple AI models across the edge network to optimize overall system performance, resource allocation, and coordination. The communication between AI models within each node and between nodes adapts to maximize the relationship of a collection of nodes.</p>



<p>For example, let&#8217;s consider a smart city infrastructure using edge computing. The infrastructure consists of various edge devices deployed throughout the city, such as traffic cameras, environmental sensors, and smart streetlights. Each device runs its AI model to perform specific tasks like traffic monitoring, air quality analysis, and intelligent lighting control.</p>



<p>In the AI-adapted choreography stage, the AI models within each device collaborate and communicate to optimize the overall performance of the smart city infrastructure. The models exchange information about traffic conditions, environmental data, and lighting requirements. Based on this information, they dynamically adapt their behavior to ensure efficient traffic flow, minimize energy consumption, and respond to changing environmental conditions.</p>



<p>Since these systems are generally developed by many organizations (different standards, different protocols), the context and the AI of each system component will also help define the protocol between the components, allowing components that are not necessarily made to communicate with each other to exchange information.</p>



<p>Mimik plays a crucial role in enabling AI-adapted choreography by providing the infrastructure for communication and coordination between the AI models across the edge network. It allows the AI models running on different devices to exchange data, share insights, and collectively make decisions to optimize the operation of the smart city infrastructure. Mimik&#8217;s edge service mesh facilitates the dynamic choreography of AI models and ensures efficient collaboration.</p>



<p>In summary, in the AI-adapted choreography stage, mimik enables the dynamic coordination and optimization of multiple AI models across an edge network, allowing them to collectively achieve better system performance, resource allocation, and coordination in complex scenarios like a smart city infrastructure.</p>



<h3 class="wp-block-heading" id="Conclusion">Conclusion</h3>



<p>The role of mimik, as mentioned in the text, is to enable these stages by treating the AI model as a part of the edge microservice running on the device. It abstracts the handling of model updates from the recognition process and facilitates the exchange of information between edge microservices. By providing a local API and creating an ad-hoc edge service mesh, mimik simplifies the development process and integration of edge computing into AI workflows.</p>



<h3 class="wp-block-heading">References</h3>



<ol start="1">
<li>&#8220;Edge Computing: A Survey&#8221; by Shi et al. (IEEE Access, 2016):
<ul>
<li>This survey paper overviews edge computing, its challenges, and potential applications, including AI at the edge.</li>
</ul>
</li>



<li>&#8220;Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing&#8221; by Satyanarayanan et al. (Proceedings of the IEEE, 2019):
<ul>
<li>This paper discusses the concept of edge intelligence, including the execution of AI models at the edge and the benefits it brings.</li>
</ul>
</li>



<li>&#8220;Bringing AI to the Edge: Distributed Learning in IoT Systems&#8221; by Yang et al. (IEEE Network, 2019):
<ul>
<li>This article explores the challenges and techniques for deploying AI models at the edge, including model training and coordination in distributed IoT systems.</li>
</ul>
</li>



<li>Official mimik documentation and resources:
<ul>
<li>To understand the specific capabilities and features of mimik in enabling edge computing and AI integration, you can refer to the official mimik documentation, whitepapers, and developer resources available on the <a href="https://mimik.com" target="_blank" rel="noopener" title="">mimik website</a> or other official channels.</li>
</ul>
</li>
</ol><p>The post <a href="https://mimik.com/the-four-stages-of-edge-ai/">The four stages of edge AI</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Endpoint Device Security, The Missing Link in SASE</title>
		<link>https://mimik.com/endpoint-device-security-the-missing-link-in-sase/</link>
		
		<dc:creator><![CDATA[Michel Burger]]></dc:creator>
		<pubDate>Fri, 20 Oct 2023 09:07:17 +0000</pubDate>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[technical]]></category>
		<guid isPermaLink="false">https://stg-2x.mimik.com/?p=79738</guid>

					<description><![CDATA[<p>Many organizations are turning to Secure Access Service Edge (SASE) solutions to fortify their security posture.</p>
<p>The post <a href="https://mimik.com/endpoint-device-security-the-missing-link-in-sase/">Endpoint Device Security, The Missing Link in SASE</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></description>
										<content:encoded><![CDATA[<h2 class="wp-block-heading" id="Introduction">Introduction</h2>



<p>In today&#8217;s rapidly evolving digital landscape, ensuring the security of endpoint devices has become more critical than ever before. The proliferation of remote work, mobile devices, and cloud-based applications has introduced new challenges for safeguarding sensitive data and maintaining network integrity. In response to these challenges, many organizations are turning to Secure Access Service Edge (SASE) solutions to fortify their security posture.</p>



<h3 class="wp-block-heading">&nbsp;</h3>



<h2 class="wp-block-heading">Traditional Security Implementation</h2>



<p>Traditional security models are often described as a &#8220;castle-and-moat&#8221; approach. In this model, the organization&#8217;s network is considered the castle, and security solutions such as firewalls and VPNs act as the moat. Everything inside the network perimeter is considered trusted, while external elements are treated with suspicion.</p>



<ol start="1">
<li>
<p data-renderer-start-pos="841"><strong data-renderer-mark="true">Perimeter-based Security:</strong> Traditional security relies on a perimeter-based model where the organization&#8217;s network is the fortress, and security solutions (firewalls, VPNs, etc.) serve as the protective moat. Elements inside the perimeter are trusted, while anything external is treated cautiously.</p>
</li>



<li>
<p data-renderer-start-pos="1142"><strong data-renderer-mark="true">Centralized Security Appliances:</strong> Security solutions, like firewalls and intrusion prevention systems, are often centralized, especially at the data center. This often results in traffic being backhauled from remote locations or branches to this central point for inspection.</p>
</li>



<li>
<p data-renderer-start-pos="1420"><strong data-renderer-mark="true">VPN for Remote Access: </strong>Remote users typically connect to the network using VPNs, which can introduce latency since traffic from remote users is tunneled to the central office before accessing the internet or other resources.</p>
</li>



<li>
<p data-renderer-start-pos="1648"><strong data-renderer-mark="true">Disparate Solutions: </strong>Traditional setups might have various standalone solutions – a firewall from one vendor, a secure web gateway from another, VPNs from another, etc. This can complicate integration and management.</p>
</li>
</ol>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2023/10/01-1024x536.jpg" alt=""/></figure></div>


<h2 class="wp-block-heading">SASE Security Implementation</h2>



<p>While traditional security implementations were well-suited for a time when most resources and users were centralized, the shift towards cloud services, remote work, and mobile users has revealed its limitations. SASE aims to address these modern challenges by offering a more flexible, integrated, and decentralized cloud-first security solution optimized for the current state of enterprise computing. Here&#8217;s how it differs:</p>



<ol start="1">
<li>
<p data-renderer-start-pos="2331"><strong data-renderer-mark="true">Identity and Context-aware Security:</strong> SASE treats every access attempt as untrusted instead of relying on a network perimeter. Access is granted based on the user&#8217;s or device&#8217;s identity, the access request&#8217;s context, real-time analytics, and other factors.</p>
</li>



<li>
<p data-renderer-start-pos="2590"><strong data-renderer-mark="true">Decentralized Security Services:</strong> Security is implemented closer to the point of access, often at the edge or as a cloud service. This means users connect to their nearest security service point, reducing latency.</p>
</li>



<li>
<p data-renderer-start-pos="2806"><strong data-renderer-mark="true">Integrated Suite of Services:</strong> SASE aims to combine various security services like Secure Web Gateways (SWG), Cloud Access Security Brokers (CASB), Firewall as a Service (FWaaS), Zero Trust Network Access (ZTNA), etc., into a unified platform. This integrated approach simplifies management and ensures that security policies are applied everywhere.</p>
</li>



<li>
<p data-renderer-start-pos="3158"><strong data-renderer-mark="true">Optimized for Cloud and Mobile: </strong>Traditional security models have shown strains as organizations have shifted to cloud services and remote work. SASE is designed with the cloud and mobility in mind, ensuring that security policies are consistently applied no matter where users are or which devices they use.</p>
</li>



<li>
<p data-renderer-start-pos="3469"><strong data-renderer-mark="true">Scalable and Flexible:</strong> Being cloud-native, SASE solutions can scale as required and adapt quickly to changing business needs.</p>
</li>
</ol>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2023/10/02-1024x581.jpg" alt=""/></figure></div>


<h2 class="wp-block-heading" id="The-Role-of-the-Device-in-SASE-Implementation">The Role of the Device in SASE Implementation</h2>



<p>While SASE drastically changes the enterprise security approach, it still considers the end-user device, whether mobile, non-mobile, or IoT, as an integral part of the security solution. In a SASE (Secure Access Service Edge) solution, the services primarily reside in the cloud, leveraging a global network of points of presence (PoPs) to provide security and networking services as close to the end-user or device.</p>



<p>However, specific components or agents might run on the end-user&#8217;s device to interact with these cloud-based services. Here&#8217;s what typically runs on the device in a SASE architecture:</p>



<ol start="1">
<li><p data-renderer-start-pos="4251"><strong data-renderer-mark="true">Endpoint Agent/Client Software:</strong> This is a lightweight software client installed on the user&#8217;s device (laptop, smartphone, tablet, etc.). The agent is responsible for:</p>
<ul>
<li>
<p data-renderer-start-pos="4421">Initiating secure connections to the SASE cloud.</p>
</li>



<li>
<p data-renderer-start-pos="4473">Enforcing local security policies.</p>
</li>



<li>
<p data-renderer-start-pos="4511">Monitoring device health and security posture.</p>
</li>



<li>
<p data-renderer-start-pos="4561">Redirecting traffic to the SASE service for security checks and policy enforcement.</p>
</li>
</ul>
</li>



<li><p data-renderer-start-pos="4650"><strong data-renderer-mark="true">Zero Trust Network Access (ZTNA) Components:</strong> ZTNA ensures that every access attempt to resources, even from within the network, is authenticated and verified. The endpoint agent often includes components to enforce ZTNA principles, such as:</p>
<ul>
<li>
<p data-renderer-start-pos="4894">Identity verification.</p>
</li>



<li>
<p data-renderer-start-pos="4920">Context-aware access controls (based on device health, location, user role, etc.).</p>
</li>



<li>
<p data-renderer-start-pos="5006">Application-level connectivity (connecting the user only to the specific applications they need, not the entire network).</p>
</li>
</ul>
</li>



<li>
<p data-renderer-start-pos="5133"><strong data-renderer-mark="true">Data Encryption Tools:</strong> The agent ensures that data in transit is encrypted when connecting to the SASE cloud or other organizational resources.</p>
</li>



<li><p data-renderer-start-pos="5280"><strong data-renderer-mark="true">Local Security Services:</strong> While most security services in a SASE architecture are cloud-based, certain local checks or policies might still be enforced on the device. This can include:</p>
<ul>
<li>
<p data-renderer-start-pos="5467">Local firewall rules.</p>
</li>



<li>
<p data-renderer-start-pos="5492">Host intrusion prevention systems.</p>
</li>



<li>
<p data-renderer-start-pos="5530">Data loss prevention checks for sensitive data.</p>
</li>
</ul>
</li>



<li><p data-renderer-start-pos="5583"><strong data-renderer-mark="true">Security Posture Check:</strong> Before granting access to resources, the SASE solution might check the device&#8217;s security posture. This can involve verifying:</p>
<ul>
<li>
<p data-renderer-start-pos="5736">Antivirus/antimalware status.</p>
</li>



<li>
<p data-renderer-start-pos="5769">Operating system and software patch levels.</p>
</li>



<li>
<p data-renderer-start-pos="5816">Compliance with organizational security policies.</p>
</li>
</ul>
</li>



<li>
<p data-renderer-start-pos="5871"><strong data-renderer-mark="true">Management and Configuration Tools:</strong> These allow IT teams to configure the agent&#8217;s behavior, update policies, and integrate with other IT management tools.</p>
</li>



<li>
<p data-renderer-start-pos="6029"><strong data-renderer-mark="true">Logging and Monitoring Components:</strong> The agent might also collect logs and other relevant data for analysis. This information can be sent to the central SASE solution for anomaly detection, analysis, and reporting.</p>
</li>
</ol>



<p>The exact components and functionalities can vary depending on the specific SASE solution provider and the organization&#8217;s requirements. However, SASE aims to keep the on-device footprint lightweight and leverage the cloud for most heavy lifting, ensuring consistent policy enforcement and optimal performance regardless of the device&#8217;s location. These aims do not consider the latest edge-in approach and microservice architecture developments, which the mimik platform enables. This includes:</p>



<ul>
<li>
<p data-renderer-start-pos="6742">Running microservices that expose API directly on devices</p>
</li>



<li>
<p data-renderer-start-pos="6803">Handling ad-hoc edge service meshes where microservices interact with each other directly without going through the cloud</p>
</li>
</ul>



<h2 class="wp-block-heading">The Role of mimik HEC in SASE</h2>



<h3 class="wp-block-heading" id="The-Role-of-the-Device-in-SASE-Implementation">Implementation</h3>



<p>Now, let&#8217;s explore how mimik <a title="https://mimik.com/mec-mimik-paper-at-ieee-5g-world-forum-2021/" href="https://mimik.com/mec-mimik-paper-at-ieee-5g-world-forum-2021/" data-testid="link-with-safety" data-renderer-mark="true" data-wplink-edit="true">Hybrid Edge Cloud (HEC) software platform</a> can contribute to the implementation of SASE, enhancing its capabilities for securing endpoint devices.</p>



<p>The mimik HEC is crucial in enhancing SASE implementation by providing innovative solutions and components that ensure secure, efficient, and context-aware protection for endpoint devices. Here&#8217;s how mimik contributes:</p>



<ol start="1">
<li>
<p data-renderer-start-pos="7372"><strong data-renderer-mark="true">Distributed Computing:</strong> mimik facilitates distributed computing at the edge, reducing latency and enabling real-time analytics and response, essential for security solutions like SASE.</p>
</li>



<li>
<p data-renderer-start-pos="7559"><strong data-renderer-mark="true">Edge Server Capabilities:</strong> Devices powered by mimik can act as edge cloud servers, deploying SASE solutions closer to data sources or users, improving performance, and reducing the load on central servers.</p>
</li>



<li>
<p data-renderer-start-pos="7767"><strong data-renderer-mark="true">Interoperability:</strong> mimik&#8217;s platform fosters interoperability between different cloud services, edge devices, and on-premises resources, a critical requirement for implementing SASE in a hybrid environment.</p>
</li>



<li>
<p data-renderer-start-pos="7975"><strong data-renderer-mark="true">Resource Optimization:</strong> Implementing SASE solutions with mimik edgeEngine on the mimik hybrid edge cloud platform can optimize network and computing resource utilization by balancing the load between cloud, edge, and on-premises.</p>
</li>



<li>
<p data-renderer-start-pos="8207"><strong data-renderer-mark="true">Enhanced Security:</strong> Integrating security microservices at the edge using mimik edgeEngine enables granular and context-aware security enforcement, essential for Zero Trust Network Access (ZTNA) and Secure Web Gateway (SWG) components of SASE.</p>
</li>
</ol>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2023/10/03-1024x623.jpg" alt=""/></figure></div>


<h3 class="wp-block-heading" id="Edge-in-Approach-with-mimik">Edge-in Approach with mimik</h3>



<p>One of the unique aspects of mimik&#8217;s contribution is the ability to move or complement SASE functions further to the edge, even directly on the user or IoT device. This approach enables a more contextualized and efficient security strategy, allowing for device-to-device interaction that is impossible in a traditional cloud-first SASE implementation.</p>



<h3 class="wp-block-heading" id="mimik's-Impact-on-Key-SASE-Components">mimik&#8217;s Impact on Key SASE Components</h3>



<p>Looking at the significant components of a SASE architecture, it is possible to understand the impact of an edge-in approach enabled by the mimik platform:</p>



<ul>
<li><p data-renderer-start-pos="9033"><strong data-renderer-mark="true">Cloud Access Security Broker (CASB):</strong> By running CASB as an edge microservice on the device itself (eCASB), organizations can benefit from:</p>
<ul>
<li>
<p data-renderer-start-pos="9175"><strong data-renderer-mark="true">Decentralized Data Management:</strong> As cloud applications proliferate, so does the data between devices and these applications. With edge computing capabilities from solutions like mimik edgeEngine, there&#8217;s potential for more localized data processing and decision-making at the data source before sending it out. This can be leveraged to inspect data locally on a device before it&#8217;s sent to or received from a cloud service, aligning with some CASB functions.</p>
</li>



<li>
<p data-renderer-start-pos="9634"><strong data-renderer-mark="true">Local Policy Enforcement:</strong> With the ability to execute applications and processes at the edge, organizations could run lightweight, localized CASB-like functions on the device. This would mean real-time policy enforcement even before data or requests hit the main CASB solution in the network path, allowing the ability to do multi-cloud brokering right from the device (at the edge) instead of in the cloud.</p>
</li>



<li>
<p data-renderer-start-pos="10045"><strong data-renderer-mark="true">Enhanced Performance:</strong> By integrating edge capabilities with CASB functionalities, certain processes can be offloaded to the edge, reducing latency. For instance, initial policy checks or data classifications, augmentation, and tagging can be done on-device, reducing the need for all traffic to be routed through a central CASB solution.</p>
</li>



<li>
<p data-renderer-start-pos="10386"><strong data-renderer-mark="true">Integration with Other Edge Services:</strong> As part of a broader edge ecosystem, CASB functionalities can be combined with other edge services, enabling more comprehensive security and data management solutions tailored for specific environments or use cases.</p>
</li>



<li>
<p data-renderer-start-pos="10643"><strong data-renderer-mark="true">Custom CASB Solutions for Unique Use Cases:</strong> Developers can potentially build custom CASB solutions tailored to specific organizational needs or niche applications, leveraging the flexibility and capabilities provided by mimik edgeEngine.</p>
</li>
</ul>
</li>



<li><p data-renderer-start-pos="10886"><strong data-renderer-mark="true">Zero Trust Network Access (ZTNA): </strong>mimik platform took a zero-trust network approach as a core feature of the edge system. This approach allows edge engine to provide the following:</p>
<ul>
<li>
<p data-renderer-start-pos="11070"><strong data-renderer-mark="true">Localized Access Control:</strong> With computing capabilities extended to the edge; access decisions might be made locally, right where the request originates. This could result in reduced latency and more efficient access controls, as not every decision must be routed through a centralized authority.</p>
</li>



<li>
<p data-renderer-start-pos="11368"><strong data-renderer-mark="true">Enhanced Security for IoT Devices:</strong> IoT devices can often be weak points in a network. If these devices are empowered with edgeEngine capabilities and integrated with ZTNA principles, they could have enhanced security postures, mitigating some of the risks associated with IoT deployments.</p>
</li>



<li>
<p data-renderer-start-pos="11660"><strong data-renderer-mark="true">Integration with Decentralized Applications:</strong> As more applications and services become decentralized and move to the edge, integrating ZTNA principles becomes crucial. Using a platform like mimik edgeEngine, developers could create applications with built-in ZTNA functionalities tailored for specific edge use cases.</p>
</li>



<li>
<p data-renderer-start-pos="11980"><strong data-renderer-mark="true">Continuous Authentication and Authorization:</strong> ZTNA emphasizes continuous verification, not just at the beginning of a session. With edge computing capabilities, this continuous check can be done more efficiently, utilizing real-time device data.</p>
</li>



<li>
<p data-renderer-start-pos="12228"><strong data-renderer-mark="true">Micro-segmentation at the Edge:</strong> ZTNA often employs micro-segmentation to isolate and protect network resources. With edgeEngine, this segmentation could be extended to the edge, providing more granular isolation and protection of resources, data, and services.</p>
</li>
</ul>
</li>



<li><p data-renderer-start-pos="12494"><strong data-renderer-mark="true">Next-Generation Firewall (NGFW): </strong>The mimik edgeEngine resides on top of the operating system and, therefore, does not have deep access to the network stack and does not enable the implementation of features like DPI. However, by implementing an API Gateway, it is possible for a microservice running within the edge engine to enable the following features:</p>
<ul>
<li>
<p data-renderer-start-pos="12854"><strong data-renderer-mark="true">Localized Traffic Inspection:</strong> With applications and services running on the edge, localized traffic inspection and filtering at the message level can potentially be done. Rather than sending all traffic through a central NGFW, initial inspections and policy checks could be performed on-device or at the edge, enhancing responsiveness and reducing unnecessary traffic loads on central security appliances.</p>
</li>



<li>
<p data-renderer-start-pos="13263"><strong data-renderer-mark="true">Context-rich Policies: </strong>The edgeEngine can provide granular, context-rich data from devices, given its edge-centric architecture. This context can be valuable for NGFW functions, allowing for dynamic and adaptive security policies based on real-time device status, user behavior, location, etc.</p>
</li>



<li>
<p data-renderer-start-pos="13560"><strong data-renderer-mark="true">Protection of IoT Devices: </strong>IoT devices, often seen as vulnerable network points, could benefit from localized firewall capabilities. By integrating NGFW functionalities at the edge, there&#8217;s potential for better security postures for IoT deployments, with immediate threat detection and response.</p>
</li>



<li>
<p data-renderer-start-pos="13859"><strong data-renderer-mark="true">Integration with Edge Services:</strong> As more services move to the edge, there&#8217;s an increasing need to ensure these services are secured. By integrating NGFW capabilities into edge-based services powered by mimik edgeEngine, there&#8217;s an opportunity for holistic security that&#8217;s tailored for edge-specific scenarios.</p>
</li>



<li>
<p data-renderer-start-pos="14171"><strong data-renderer-mark="true">Decentralized Threat Detection and Response: </strong>By leveraging edge computing capabilities, threat detection and response can potentially be decentralized. If an anomaly or potential threat is detected on a device or within a network segment, immediate action can be taken at the edge, even before the central NGFW or security operations center is alerted.</p>
</li>



<li>
<p data-renderer-start-pos="14527"><strong data-renderer-mark="true">Scalability and Adaptability:</strong> With the growth of connected devices and increasing network complexity, scalability becomes a concern for traditional NGFWs. By offloading some functionalities to the edge, there&#8217;s potential for more scalable security solutions that adapt to changing network conditions and demands.</p>
</li>
</ul>
</li>



<li><p data-renderer-start-pos="14845"><strong data-renderer-mark="true">Secure Web Gateway (SWG): </strong>Allowing microservice to run directly on the device on top of the mimik edgeEngine and this behind an API Gateway, it is possible to enable an eSWG which will have the following capabilities:</p>
<ul>
<li>
<p data-renderer-start-pos="15066"><strong data-renderer-mark="true">Real-time Content Filtering:</strong> An eSWG running on the device can provide real-time content filtering, blocking malicious or inappropriate content before it reaches the user&#8217;s device.</p>
</li>



<li>
<p data-renderer-start-pos="15250">Local Policy Enforcement: Organizations can implement customized content filtering policies at the edge, ensuring that users are protected from web-based threats even when they are not connected to the corporate network.</p>
</li>



<li>
<p data-renderer-start-pos="15474"><strong data-renderer-mark="true">Reduced Latency:</strong> By offloading content filtering to the edge, latency is minimized, resulting in faster web access for users.</p>
</li>



<li>
<p data-renderer-start-pos="15603"><strong data-renderer-mark="true">Improved Performance:</strong> An eSWG can optimize web traffic, reducing the load on central SWG solutions and improving overall network performance.</p>
</li>



<li>
<p data-renderer-start-pos="15748"><strong data-renderer-mark="true">Integration with Local Services:</strong> Organizations can integrate their eSWG with other local services and security components to provide a comprehensive security posture.</p>
</li>



<li>
<p data-renderer-start-pos="15918"><strong data-renderer-mark="true">Enhanced Privacy: </strong>With an eSWG at the edge, user data remains on the device, enhancing privacy and reducing the need to send user data to centralized SWG solutions.</p>
</li>
</ul>
</li>
</ul>



<h3 class="wp-block-heading" id="Conclusion">&nbsp;</h3>



<h2 class="wp-block-heading" id="Conclusion">Conclusion</h2>



<p id="Conclusion">Securing endpoint devices is paramount in the ever-evolving landscape of cybersecurity and remote work. Traditional security models have limitations, especially in the face of the cloud, mobility, and the Internet of Things (IoT). Secure Access Service Edge (SASE) represents a new paradigm in security, offering an integrated, cloud-native, and context-aware approach. The mimik HEC is pivotal in enhancing SASE implementation by enabling distributed computing at the edge, fostering interoperability, and providing the tools for secure, efficient, and context-aware protection. By moving or complementing SASE functions to the edge, mimik&#8217;s innovative approach enhances security, reduces latency, and opens new possibilities for device-to-device interactions, bolstering the security posture of organizations in a rapidly changing digital world. With SASE and mimik, the future of endpoint security looks brighter, more efficient, and more resilient than ever before.</p><p>The post <a href="https://mimik.com/endpoint-device-security-the-missing-link-in-sase/">Endpoint Device Security, The Missing Link in SASE</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Beyond Boundaries: Enabling Performance and Security with API Gateways Everywhere</title>
		<link>https://mimik.com/beyond-boundaries/</link>
		
		<dc:creator><![CDATA[Michel Burger]]></dc:creator>
		<pubDate>Wed, 16 Aug 2023 02:00:00 +0000</pubDate>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[technical]]></category>
		<guid isPermaLink="false">https://stg-2x.mimik.com/?p=79190</guid>

					<description><![CDATA[<p>In a cloud-first architecture, API gateways play a crucial role in enabling communication between different cloud services and applications.</p>
<p>The post <a href="https://mimik.com/beyond-boundaries/">Beyond Boundaries: Enabling Performance and Security with API Gateways Everywhere</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>In a cloud-first architecture, API gateways play a crucial role in enabling communication between different cloud services and applications. They act as a central point of control and provide a unified interface to the clients, making it easier to manage and monitor the overall system.&nbsp; API gateways also provide a layer of abstraction between the client and the cloud services hence allowing developing different applications while still using the same services.</p>



<p>In essence, an API gateway is a server that acts as an intermediary between the client and the cloud services performing many tasks such as authentication, rate limiting, caching, and protocol translation. Therefore, the API gateway can improve the performance, scalability, and security of the overall system architecture. It is commonly used in microservices and serverless architectures.</p>



<p>In the conventional API Gateway market, various vendors offer API Gateway solutions for managing, securing, and exposing APIs to external or internal applications. The main players are Amazon API Gateway, Kong, Rapid, Google Cloud (Apigee) and Azure API Management, among others. They offer different solutions based on their functionality and features such as Proxy, Transformation Gateways, Security, Orchestration and Monetization. Developers can choose the right one according to their specific requirements and use cases.</p>



<p>Examining this offering, we can identify three distinct types of API gateways: façade, exposure, and listening endpoint.</p>



<p>The first one, the API Gateway, acts as a facade for service implementations that operate in separate environments. The API Gateway serves as a single-entry point for all incoming API requests, abstracting the complexity of underlying microservices or distributed systems. These gateways are engineered to manage specific protocols such as HTTP and WebSocket, and they primarily focus on addressing security concerns, particularly TLS security. By using an API Gateway as a facade, organizations can simplify the management of their APIs and services, improve security, and enhance the developer experience for API consumers.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" width="737" height="386" src="https://mimik.com/wp-content/uploads/2024/01/img-01.jpg" alt="" class="wp-image-82680" srcset="https://mimik.com/wp-content/uploads/2024/01/img-01.jpg 737w, https://mimik.com/wp-content/uploads/2024/01/img-01-300x157.jpg 300w" sizes="(max-width: 737px) 100vw, 737px" /></figure></div>


<p>The second one, often call API Exposure Gateway, is an API Gateway which alters or enhances the implemented API that runs on a different environment. It focuses on making APIs accessible to external consumers, partners, or third-party developers. The main goal of an API Exposure Gateway is to facilitate secure, controlled, and efficient access to APIs while ensuring a positive developer experience. It can implement business logic, including caching, throttling, and even metering for billing purposes. API Exposure Gateways are crucial for businesses looking to expose their APIs to a broader audience, foster innovation, and create new revenue streams through API monetization. By providing a secure and controlled environment for API consumption, these gateways enable organizations to maximize the value of their APIs while minimizing risks.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" width="737" height="386" src="https://mimik.com/wp-content/uploads/2024/01/img-02.jpg" alt="" class="wp-image-82681" srcset="https://mimik.com/wp-content/uploads/2024/01/img-02.jpg 737w, https://mimik.com/wp-content/uploads/2024/01/img-02-300x157.jpg 300w" sizes="(max-width: 737px) 100vw, 737px" /></figure></div>


<p>The last one, the listening endpoint API terminates the network connection, is commonly utilized in serverless environments to instantiate the process required for executing the operation requested by the API call. This endpoint acts as an entry point for clients to access the functionality provided by the API, and it&#8217;s responsible for processing incoming requests, executing the appropriate actions, and returning the expected responses. In most cases, the API and the service function within the same environment.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img loading="lazy" decoding="async" width="737" height="386" src="https://mimik.com/wp-content/uploads/2024/01/img-03.jpg" alt="" class="wp-image-82683" srcset="https://mimik.com/wp-content/uploads/2024/01/img-03.jpg 737w, https://mimik.com/wp-content/uploads/2024/01/img-03-300x157.jpg 300w" sizes="(max-width: 737px) 100vw, 737px" /></figure></div>


<p>Though the gateways vary in their execution, their primary goal remains consistent to act as a central entry point and intermediary for managing, securing, and exposing APIs of cloud services to external consumers or internal applications. It enables cloud services to be utilized by other cloud services or client applications without needing to comprehend the service&#8217;s inner workings. This gateway can operate in the cloud or near the client applications as an edge cloud broker.</p>



<p>Suppose for a moment, this cloud-centric approach didn&#8217;t exist, and it was feasible to run microservices (or functions as a service) at the edge within the device or system hosting client applications. In that case, a reverse API gateway becomes necessary to expose these microservices. However, instead of exposing cloud services to client applications, it focuses on exposing edge microservices services to either client applications or other edge microservices running on different nodes or cloud services. Consequently, each node within a system serves as an individual server running microservices with exposed APIs at the software level, establishing a ad hoc edge service mesh among all nodes capable of discovering one another.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img loading="lazy" decoding="async" width="815" height="500" src="https://mimik.com/wp-content/uploads/2024/01/img-04.jpg" alt="" class="wp-image-82684" srcset="https://mimik.com/wp-content/uploads/2024/01/img-04.jpg 815w, https://mimik.com/wp-content/uploads/2024/01/img-04-300x184.jpg 300w, https://mimik.com/wp-content/uploads/2024/01/img-04-768x471.jpg 768w" sizes="(max-width: 815px) 100vw, 815px" /></figure></div>


<p>In this edge first scenario, the reverse gateway would function as a local API Gateway, managing the microservices within the device itself. It would have a vital role in managing and securing the communication between microservices and client applications. By functioning as a local API Gateway, it would manage, secure, and optimize API traffic within the device or system, providing a unified entry point for accessing microservices and improving overall performance and security. Moreover, the local API Gateway would also enable better resource utilization and faster response times as the microservices would be running in the same environment as the client applications.</p>



<p>This reverse API gateway is a natural next step in the evolution of the API Architecture, well described in the Netflix technology blog.</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img loading="lazy" decoding="async" width="978" height="600" src="https://mimik.com/wp-content/uploads/2024/01/img-05.jpg" alt="" class="wp-image-82686" srcset="https://mimik.com/wp-content/uploads/2024/01/img-05.jpg 978w, https://mimik.com/wp-content/uploads/2024/01/img-05-300x184.jpg 300w, https://mimik.com/wp-content/uploads/2024/01/img-05-768x471.jpg 768w" sizes="(max-width: 978px) 100vw, 978px" /></figure></div>


<p>Left to right: 1) Accessing the monolith via a single API, 2) Accessing microservices via separate APIs, 3) Using a single API gateway, 4) Accessing groups of microservices via multiple API gateways. Source: <em>Netflix Technology Blog</em></p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img loading="lazy" decoding="async" width="1024" height="520" src="https://mimik.com/wp-content/uploads/2024/01/img-06-1024x520.jpg" alt="" class="wp-image-82688" srcset="https://mimik.com/wp-content/uploads/2024/01/img-06-1024x520.jpg 1024w, https://mimik.com/wp-content/uploads/2024/01/img-06-300x152.jpg 300w, https://mimik.com/wp-content/uploads/2024/01/img-06-768x390.jpg 768w, https://mimik.com/wp-content/uploads/2024/01/img-06.jpg 1182w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure></div>


<p>Edge microservice can either access each other edge microservice on different nodes directly without going thru the cloud via reverse API gateway or access cloud microservice via a single API gateway.</p>



<p>The concept of device-as-a-service will then be established, allowing client applications to utilize features from a single device or a collection of devices through a series of APIs without needing to comprehend the inner workings of the implementation. This will spark a surge in innovation as it enables the development of applications using systems without requiring expertise in those specific systems. As an example, considering the automobile industry&#8217;s ongoing shift towards SDV, it is crucial to begin revealing car functionalities to developers outside of the automotive realm to harness the creative potential within the mobile app industry. A reverse API gateway is essential for accomplishing this objective.</p>



<p>mimik&#8217;s edgeEngine provides this reverse API gateway, enabling each node to serve as a data source at the application level. mimik’s edgeEngine allows client applications to utilize features from a single device or a collection of devices through a series of APIs without needing to comprehend the inner workings of the implementation. This edegEngine comprises an API gateway, an OS-agnostic runtime environment, a discovery service for nodes and edge microservices, and an edge analytic platform that enables each node to serve as a data source at the application level. This enables the development of applications using systems without requiring expertise in those specific systems, sparking a surge in innovation.</p><p>The post <a href="https://mimik.com/beyond-boundaries/">Beyond Boundaries: Enabling Performance and Security with API Gateways Everywhere</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>mimik for Digital Twin</title>
		<link>https://mimik.com/mimik-for-digital-twin/</link>
		
		<dc:creator><![CDATA[Michel Burger]]></dc:creator>
		<pubDate>Thu, 10 Aug 2023 06:34:01 +0000</pubDate>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[technical]]></category>
		<guid isPermaLink="false">https://stg-2x.mimik.com/?p=79436</guid>

					<description><![CDATA[<p>mimik for Digital Twin</p>
<p>The post <a href="https://mimik.com/mimik-for-digital-twin/">mimik for Digital Twin</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></description>
										<content:encoded><![CDATA[<h2 id="Abstract" data-renderer-start-pos="1">Abstract</h2>
<p data-renderer-start-pos="11">A digital twin is a virtual representation of a physical object, process, or system. It is a computerized model that simulates the behavior of a real-world object or system in real-time, providing a detailed and accurate reflection of its physical counterpart.</p>
<p data-renderer-start-pos="273">A digital twin is created by collecting data from various sources, such as sensors, cameras, and other IoT devices, and processing that data using machine learning algorithms and other analytical tools. The resulting model can monitor, analyze, and optimize the physical system&#8217;s performance and predict future behavior and outcomes.</p>
<p data-renderer-start-pos="608">Digital twins are commonly used in manufacturing, aerospace, and energy industries. They can be used to simulate the operation of complex machinery, equipment, and systems and identify potential issues or inefficiencies before they occur in the real world. They are also used in building design and construction to optimize performance, maintenance, and energy efficiency.</p>
<p data-renderer-start-pos="982">A digital twin is composed of two main steps:</p>
<ol start="1" data-indent-level="1">
<li>
<p data-renderer-start-pos="1032">development phase, pre-production (aka pre-prod)</p>
</li>
<li>
<p data-renderer-start-pos="1084">deployment and update phase in production (aka post-prod)</p>
</li>
</ol>
<h2 id="Pre-prod-digital-twin" data-renderer-start-pos="1145">Pre-prod digital twin</h2>
<p data-renderer-start-pos="1168">Looking at the lifecycle development of a solution that involves embedded software components (a car, a manufacturing line, etc..) utilizing QNX, many variants of Linux, Android, and even IOS when a user phone is involved, a developer implementing a new feature does not have the actual environment available as a cloud developer has a Development Environment, aka DEV, to do the implementation and QA for testing the compliance of the implementation. To remediate this problem, a simulation of the environment has to be created. This is where the need for a pre-prod digital twin is emerging.</p>
<p data-renderer-start-pos="1763">Adopting modern development solutions and creating an environment in the cloud is a natural solution for such simulation. And because in a cloud environment, the resource is virtualized and generally pooled using Kubernetes orchestrator, a natural consequence is to containerize every simulation component. The developer implementing a new feature must dynamically deploy images and containers using Kubernetes.</p>
<p data-renderer-start-pos="2176">This will work well assuming two following conditions:</p>
<ol start="1" data-indent-level="1">
<li>
<p data-renderer-start-pos="2234">Any legacy software that runs in an actual environment needs to be containerized.</p>
</li>
<li>
<p data-renderer-start-pos="2319">The simulation in the cloud environment must closely mimic the actual environment.</p>
</li>
</ol>
<p data-renderer-start-pos="2406">These two conditions are difficult to realize since, in the actual environment for embedded systems, the usage of real-time operating systems is frequent, and containerizing legacy components has limitations when dealing with user interfaces and multi-processes within the same container. This means that once QA is passed in the cloud, transferring the new feature to the actual environment generally leads to new problems, making the whole cloud testing obsolete.</p>
<p data-renderer-start-pos="2874">Another approach to creating a pre-prod digital twin is replicating the actual environment in the cloud. For that, it is often necessary to run an RTOS like QNX. However, as most of the container technologies (e.g., docker) depend on Operation System’s functions (e.g., c-group), it is not possible to run these containers on QNX. This is why there is a need for a technology that provides a run-time independent from the operating system. And this is what mimik edgeEngine provides.</p>
<p data-renderer-start-pos="3360">Running QNX in the cloud and mimik edgeEngine on top of QNX in the cloud allows a developer to implement microservices or function-as-a-service. It is possible to have a seamless transition from the pre-prod digital twin to the actual environment.</p>
<h2 id="Post-prod-digital-twin" data-renderer-start-pos="3609">Post-prod digital twin</h2>
<p data-renderer-start-pos="3633">Once the feature is deployed in real systems, it is essential to have a feedback loop to refine the simulation. It allows developers and system analysts to understand the behavior of the actual system and how these behaviors match the behavior of the simulated environment. And this is where a post-prod digital twin needs to be created.</p>
<p data-renderer-start-pos="3973">One solution is to use the pre-prod digital twin instance to implement the post-prod digital twin. However, this implies the need to transfer a large amount of data to replicate in the cloud the context of the actual environment. This can be a source of many problems:</p>
<ol start="1" data-indent-level="1">
<li>
<p data-renderer-start-pos="4245"><strong data-renderer-mark="true">Cost:</strong> the more data to be transferred, the more cost will be generated, either the cost of transport or the cost of processing, in particular, if it is to deal with low-level signals.</p>
</li>
<li>
<p data-renderer-start-pos="4432"><strong data-renderer-mark="true">Power consumption: </strong>it generally consumes more power to transmit data to a network than to process data locally and transmit results.</p>
</li>
<li>
<p data-renderer-start-pos="4569"><strong data-renderer-mark="true">Privacy:</strong> in some cases, the data to be transmitted is about the user and, therefore, transmitted data to the cloud may be breaching privacy regulation</p>
</li>
</ol>
<p data-renderer-start-pos="4723">One solution is to split the pre-prod digital twin into two parts, one part running in that existing system and the other as a consolidation in the cloud since one aspect of running in the cloud is to deal with multiple actual systems (e.g., cars) and therefore avoid bias when extracting a generic behavior.</p>
<p data-renderer-start-pos="5033">Technology is needed to allow microservices to run in any environment (regular OS. real-time OS, main CPU, controllers) to do the pre-analysis and send smart signals to an aggregated simulation running in the cloud. And this is what mimik edgeEngine and its different editions (standard, main/child, controller/worker) provide.</p><p>The post <a href="https://mimik.com/mimik-for-digital-twin/">mimik for Digital Twin</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Harnessing the Power of Hybrid Edge Cloud: Revolutionizing App Development with mimik</title>
		<link>https://mimik.com/harnessing-the-power-of-hybrid-edge-cloud-revolutionizing-app-development-with-mimik/</link>
		
		<dc:creator><![CDATA[Fay Arjomandi]]></dc:creator>
		<pubDate>Wed, 19 Jul 2023 17:00:00 +0000</pubDate>
				<category><![CDATA[Blog]]></category>
		<guid isPermaLink="false">https://mimik.com/?p=81264</guid>

					<description><![CDATA[<p>Introduction Recently, I have been receiving numerous inquiries from individuals who are intrigued by the concept of Hybrid Edge Cloud (HEC). They are keen to understand its practical applications and which types of applications can benefit the most from this innovative approach. In response to their curiosity, I have decided to shed some light on [&#8230;]</p>
<p>The post <a href="https://mimik.com/harnessing-the-power-of-hybrid-edge-cloud-revolutionizing-app-development-with-mimik/">Harnessing the Power of Hybrid Edge Cloud: Revolutionizing App Development with mimik</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></description>
										<content:encoded><![CDATA[<p id="4f03"><strong>Introduction</strong></p>



<p id="5e18">Recently, I have been receiving numerous inquiries from individuals who are intrigued by the concept of Hybrid Edge Cloud (HEC). They are keen to understand its practical applications and which types of applications can benefit the most from this innovative approach. In response to their curiosity, I have decided to shed some light on the versatility of HEC as a modern approach for cloud-native applications. While it is applicable to all applications, I will also highlight specific use cases that exemplify its potential and advantages.</p>



<p id="dbce">In today’s rapidly evolving digital landscape, app developers are constantly seeking ways to optimize their applications. The HEC from mimik provides a revolutionary solution that combines the power of edge computing and cloud computing. It offers a host of benefits such as enhanced performance, reduced latency, data privacy, scalability, and cost and energy efficiency. This powerful combination has piqued the interest of developers across various industries.</p>



<p id="f5ce">In this blog, I aim to demystify the concept of HEC and explain why it is a modern approach suitable for all cloud-native applications. Additionally, I will delve into specific use cases that highlight the remarkable potential of HEC, showcasing its transformative impact in real-world scenarios.</p>



<p id="322a">Let’s dive in and explore how HEC can revolutionize app development, optimize performance, and unlock new possibilities for innovation.</p>



<p id="482f"><strong>Understanding Hybrid Edge Cloud (HEC)</strong></p>



<p id="03a9">HEC represents the convergence of edge computing and cloud computing, combining the best of both worlds. With mimik’s platform, developers can leverage the power of local smart devices as cloud servers capable of deploying microservices and the central cloud to enhance their applications’ performance, scalability, and flexibility.</p>



<p id="1017"><strong>Seamless App Integration</strong></p>



<p id="37f8">One of the key advantages of mimik’s HEC platform is its seamless integration with existing app development processes. Regardless of the programming languages or frameworks you prefer, mimik supports a wide range of options, enabling you to build applications using the tools you’re already familiar with. Furthermore, the platform is built fully at the application level and works across various operating systems and device types, ensuring your applications can run seamlessly on different platforms.</p>



<p id="5c81"><strong>Enhanced Performance and Latency Reduction</strong></p>



<p id="cea0">Latency can make or break user experiences, especially in applications that require real-time interactions. HEC can drastically reduce latency by minimizing network round trips while leveraging the computing resources on smart devices. This approach results in faster response times and improved user experiences. Whether it’s a video streaming application, a real-time multiplayer game, or an IoT-based solution, the HEC ensures optimal performance for your applications.</p>



<p id="6b6d"><strong>Data Privacy and Security</strong></p>



<p id="b7ac">In an era of increasing data breaches and privacy concerns, protecting user data is paramount. With HEC, app developers can keep sensitive data on local smart devices, reducing the risk of unauthorized access or data breaches. By minimizing the need to transfer sensitive information to the cloud, developers can maintain greater control over data privacy and security. mimik’s platform also employs robust trustless security measures and encryption protocols, further safeguarding user data.</p>



<p id="d646"><strong>Scalability and Cost Efficiency</strong></p>



<p id="9d0a">Scaling applications based on demand is a crucial aspect of app development. HEC enables developers to scale their applications effortlessly. By distributing computing resources across a network of smart devices, developers can handle increased workloads without relying solely on dedicated cloud infrastructure. This results in improved scalability and cost efficiency, as developers can optimize resource utilization and reduce reliance on extensive cloud resources.</p>



<p id="acfc"><strong>Real-World Use Cases</strong></p>



<p id="fc17">HEC has found significant applications in various industries, showcasing its remarkable capabilities. Let’s explore two specific examples: automotive and industrial IoT. These use cases demonstrate the transformative impact of HEC.</p>



<p id="973b">Software-defined vehicles (SDVs) offer the advantage of adaptability and improvement through software updates, like smartphones. With separate hardware and software components, SDVs can harness technological advancements like hyper-personalization, autonomous driving, and safety features without costly hardware upgrades. This flexibility ensures up-to-date functionality, enhanced user experiences, and prolonged vehicle lifespan.</p>



<p id="50a0">When combined with mimik’s HEC, SDVs gain two additional benefits. First, HEC reduces network dependency for SDVs. Traditional SDVs are often susceptible to network availability issues, which can hinder their operations. By leveraging mimik’s HEC, vehicle functions, exposed as function-as-a-service, can be meshed with various other functions at the edge of the network. This reduces reliance on a centralized network infrastructure, making SDVs more resilient to network conditions and enhancing their overall operational reliability.</p>



<p id="73f0">Second, HEC enables hyper-personalization at the local level. SDVs have the capability to interact with multiple systems and devices, such as infotainment units and Telematics Control Units (TCUs) inside the vehicle, passenger smartphones, and smart city infrastructure. By leveraging HEC, SDVs seamlessly integrate and communicate with these vertically incompatible systems, facilitating a high degree of personalization for each user. This empowers SDVs to offer tailored experiences based on individual context and preferences, whether it’s adjusting the cabin environment, entertainment options, or personalized assistance features. HEC’s edge computing capabilities enable efficient and localized data processing, enabling SDVs to deliver real-time personalized experiences without heavy reliance on centralized cloud-based services.</p>



<p id="5513">Similarly, in industrial IoT applications, such as those found in the energy and mining sectors, connectivity to the cloud can be poor, expensive, or nonexistent. Energy and mining companies can leverage mimik’s HEC to overcome these challenges. By deploying edge endpoints and utilizing local computing resources, IoT devices can process and analyze data on-site, enabling real-time monitoring, predictive maintenance, and optimization of critical processes. This empowers companies to make timely decisions, improve operational efficiency, and reduce costs associated with transferring massive amounts of data to the cloud.</p>



<p id="1125"><strong>Conclusion</strong></p>



<p id="7e4e">HEC empowers app developers with enhanced performance, reduced latency, data privacy, scalability, and cost efficiency. It finds practical applications in various industries, showcasing its remarkable capabilities. For the automotive industry, HEC empowers software-defined vehicles (SDVs) to function as local services, seamlessly integrating with local systems even in environments with limited network connectivity. In the energy and mining sectors, where cloud connectivity is often poor or nonexistent, mimik’s platform allows for on-site data processing, improving real-time monitoring and decision-making while keeping mission critical data private and secure.</p>



<p id="9161">These examples highlight the transformative impact of HEC, but it’s important to recognize that its benefits extend to a wide range of cloud-native applications. Whether it’s healthcare, retail, smart homes, or any other domain, HEC offers a pragmatic solution that enhances performance, reduces latency, ensures data privacy, enables scalability, and optimizes cost and energy efficiency.</p>



<p id="363b">By seamlessly integrating edge computing and cloud computing, mimik’s platform unlocks new possibilities for innovation, providing developers with the tools to create cutting-edge applications that meet the evolving needs of consumers and enterprises. It bridges the gap between local smart devices and the cloud, allowing for distributed computing and improved user experiences.</p><p>The post <a href="https://mimik.com/harnessing-the-power-of-hybrid-edge-cloud-revolutionizing-app-development-with-mimik/">Harnessing the Power of Hybrid Edge Cloud: Revolutionizing App Development with mimik</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>The Journey to Autonomy: Unleashing the Power Within</title>
		<link>https://mimik.com/the-journey-to-autonomy-unleashing-the-power-within/</link>
		
		<dc:creator><![CDATA[Fay Arjomandi]]></dc:creator>
		<pubDate>Sun, 28 May 2023 21:45:00 +0000</pubDate>
				<category><![CDATA[Blog]]></category>
		<guid isPermaLink="false">https://mimik.com/?p=81259</guid>

					<description><![CDATA[<p>Once upon a time, there lived a young and curious infant named Alex. Alex was a bright and adventurous boy, always eager to explore and learn from the world around him. As he grew older, his physical abilities and understanding of the world deepened. In his early years, Alex relied on simple means to fulfill [&#8230;]</p>
<p>The post <a href="https://mimik.com/the-journey-to-autonomy-unleashing-the-power-within/">The Journey to Autonomy: Unleashing the Power Within</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></description>
										<content:encoded><![CDATA[<p id="669e">Once upon a time, there lived a young and curious infant named Alex. Alex was a bright and adventurous boy, always eager to explore and learn from the world around him. As he grew older, his physical abilities and understanding of the world deepened.</p>



<p id="27ad">In his early years, Alex relied on simple means to fulfill his needs. When hungry, he would cry out for attention, signaling his desire for nourishment. Like any caring parents, his mom and dad would respond by preparing a meal for him. But as Alex continued to learn and develop, something extraordinary happened — he started to become more and more autonomous.</p>



<p id="8f99">No longer needing to cry for every meal, Alex’s mind evolved into a complex system of interconnected thoughts and capabilities. With a simple thought, he could decide whether to cook a meal at home using his own skills or venture out to discover the diverse culinary offerings of the city. He had become a self-sufficient entity, relying on his own intelligence and resources to navigate the world.</p>



<p id="658e">In this captivating analogy, Alex’s journey from infancy to autonomy mirrors the evolution our digital world needs. Today, internet applications are like Alex in his infancy, reliant on external resources and centralized cloud architecture for even the most basic tasks. However, for true autonomy to flourish, a transformation is required — a transition from dependence on centralized infrastructure to leveraging the local resources of the devices they run on, just like Alex relies on his brain and body parts as an adult.</p>



<p id="eb55">Hybrid edge cloud (HEC) empowers these internet applications to tap into the local resources of the devices they reside on, like how Alex relies on his brain and body parts to function. It is a paradigm shift that unlocks the true power within, enabling applications to operate autonomously, adapt to their surroundings, and harness the potential of their host devices. Much like Alex’s transformation into a self-sufficient being, this transition from infancy to adulthood allows internet applications to mature and become capable of independent decision-making, reducing reliance on external resources.</p>



<p id="2325">By embracing this new era of technological innovation, we pave the way for an AI-enabled world where intelligent things can operate independently and make intelligent decisions. HEC acts as the missing link that harnesses the power of local computing resources available on each device. It reduces latency, improves performance, and enables real-time decision-making. Much like Alex’s journey towards autonomy, HEC fosters an environment where internet applications can mature and grow, mirroring the growth of Alex into an autonomous being.</p>



<p id="168a">As we embark on this journey, the power within acts as a catalyst, empowering each internet application to unleash its true potential. By leveraging the local resources of the devices they run on, we can usher in a future where applications operate autonomously, tap into their own intelligence, and redefine the boundaries of what is possible.</p>



<p id="f482">So let us embark on this remarkable adventure, where the possibilities are endless, and the potential for innovation knows no bounds. By embracing the power within, internet applications can transcend their infancy and become autonomous, mature entities that choreograph their own destinies.</p><p>The post <a href="https://mimik.com/the-journey-to-autonomy-unleashing-the-power-within/">The Journey to Autonomy: Unleashing the Power Within</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>A primer to geolocation detection on the Edge</title>
		<link>https://mimik.com/a-primer-to-geolocation-detection-on-the-edge/</link>
		
		<dc:creator><![CDATA[Bob Reselman]]></dc:creator>
		<pubDate>Thu, 26 Jan 2023 08:03:51 +0000</pubDate>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Bob Reselman]]></category>
		<guid isPermaLink="false">https://stg-2x.mimik.com/?p=78891</guid>

					<description><![CDATA[<p>There are two types of devices in Edge Computing, fixed and mobile.</p>
<p>The post <a href="https://mimik.com/a-primer-to-geolocation-detection-on-the-edge/">A primer to geolocation detection on the Edge</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>There are two types of devices in Edge Computing, fixed and mobile. Examples of fixed devices are red-light traffic cameras, internet-aware refrigerators, smart TVs, and cash registers in a point-of-sale system. Examples of mobile devices are tablets, cell phones, and forklifts. Fixed devices are, as the name implies, stationery. They don’t move around. For example, once a traffic camera is installed on a city’s street corner, it doesn’t move. Same with an internet-aware refrigerator; you put it in, plug it in and connect it to the internet. The fridge doesn’t move around your home. It stays anchored in your kitchen.</p>



<p>Suppose for some reason, you need to make the location of your internet-enabled refrigerator known to outside parties. In that case, the typical process is to do some sort of online registration with the manufacturer in which you associate the refrigerator’s serial number with your physical address. Then, messages sent over the internet from the refrigerator can bind the machine’s IP address to the serial number. All this information is stored in a database somewhere. Hence, the physical location of the refrigerator is discoverable.</p>



<p>Mobile devices, on the other hand, do move around. Thus, determining their location is not a matter of doing an address lookup in a database. The device needs to figure out where it is as its location changes. The precision of determining the location will vary, anywhere from a few inches to a few kilometers, depending on how the location of the device is detected. In some cases, a margin of error of a few kilometers might not matter. In other cases, being off by a kilometer can be a catastrophe. Thus, understanding the different ways of detecting the location of an edge device matters. Hence, the purpose of this article: to describe the various techniques for detecting the geolocation of edge devices.</p>



<p>In this article, we’re going to examine three techniques. The first is determining a device’s location using an IP address. The second is using GPS (Global Positioning System) and Differential Global Positioning System (DGPS). The third way we’re going to examine is an interesting alternative to the other two. Each method has benefits and tradeoffs that are worth understanding.</p>



<p>But before we go into these details, it is helpful to understand the essential principle of location detection: a subject never really knows where it is. Some sort of external, objective reference mechanism is needed.</p>



<p>Let’s take a moment to explore the principle.</p>



<p>Imagine that you closed your eyes to take a brief nap. Then, you wake up to find yourself lying in a country meadow. All you can see are birds and flowers and a tree or two. All that’s about you is nature. That’s the good news. The bad news is you don’t know where you are. Your surroundings are unfamiliar. There are no road signs around. You don’t have your cell phone with you, so you can’t do an automatic discovery using GPS.</p>



<p>You start walking through the meadow. A stranger approaches and you ask her where you are. She says, “Clarke County”. You have no idea of where Clarke County is, and you don’t have the lookup capabilities to figure it out. So, you still don’t know where you are.</p>



<p>You keep walking and come across another stranger. You ask the same question, “Where am I?” He responds, “Iowa.” You put two and two together and infer that you are in Clarke County, IA. You know where Iowa is, but you still have no idea where Clarke County is. The fact is that while you have a general idea of where you are, you could be in eastern, central, or western Iowa. Your operational margin of error is hundreds of miles. To have a clearer idea, you’d need some objective reference instrument, for example, a map of Iowa that includes a generally accepted coordinate system.</p>



<p>The interesting thing about all this is that absent any referencing mechanism and a quantitative way to interpret the information from that mechanism, the only thing you know about your location at any given moment is that you are “here.” The same is true of edge devices. You need an external agent to tell you where the device is and a frame reference to understand the information you’re being given. In short, if you want to know where you are, you need a map and know how to use the coordinate system supported by that map.</p>



<p>This may seem tangential in terms of detecting the location of edge devices. Still, it is an important understanding, particularly when considering very sophisticated types of edge devices, for example, interplanetary satellites.</p>



<p>Now that we’ve covered this basic understanding let’s look at the first way to detect the location of an edge device: using a device’s IP address.</p>



<h2 class="wp-block-heading">Geolocation detection using an IP Address</h2>



<p>Every device on the Internet has an IP address. It doesn’t matter if the device is on a public network or running privately behind a firewall or cable modem; it will have an IP address. That IP address does not appear by magic. It’s assigned by another mechanism. That mechanism can be a human or script that manually assigns an IP address, or the IP address can be assigned dynamically within a predefined range of addresses by a DNS server. For the most part, the physical location of the device to which the IP address is assigned can be discovered by doing a lookup of the IP address against some authority that keeps track of public IP addresses and their location, for example,&nbsp;<a href="https://www.arin.net/">ARIN</a>&nbsp;or&nbsp;<a href="https://www.ripe.net/collections-area/ripe-community/what-is-ripe">RIPE</a>. Thus, it’s possible to do a general estimation of the geographical location of an IP address. But these calculations are typically rough and can have a wide margin of error.</p>



<p>In order to make the point, we conducted an experiment in which we submitted a subject’s IP address to a variety of IP address lookup services using the tool&nbsp;<a href="https://dnschecker.org/ip-location.php">DNSChecker.org</a>. The goal was to determine the physical location that corresponded to the submitted IP. The IP address we used was 24.80.2.109. The results of the lookup by the various IP address lookup services are displayed in Table 1 below, along with the distance from the actual location of the submitted IP address.</p>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2023/01/table-768x290.png" alt=""/></figure></div>


<p><strong>Table 1: The physical latitude and longitude for the same IP according to a variety of lookup services</strong></p>



<h2 class="wp-block-heading">Geolocation detection using GPS</h2>



<p>The way that the&nbsp;<a href="https://www.gps.gov/systems/gps/performance/accuracy/">Global Positions System</a>&nbsp;(GPS) works is that there are 27 GPS satellites orbiting the Earth, of which 24 satellites are active, while the remaining three satellites provide backup in case one of the active satellites fails. These satellites emit radio waves that are intercepted by a GPS receiver on the ground.</p>



<p>The GPS receiver uses radio waves from three satellites to triangulate the receiver’s location. The location of the edge device can be determined based on latitude, longitude, and elevation, with a margin of error of six feet in 95% of cases.</p>



<p>Most modern cell phones and tablets have a GPS receiver built in. In cases where an edge device does not have one built-in, a GPS receiver can be attached. Adding an attachment is typical for enabling GPS on a small computer such as a Raspberry Pi.</p>



<p>Using GPS detection helps determine the location of a passenger pickup for a rideshare application. However, it will only give you the degree of accuracy you need if you’re trying to determine how close you are to another car when driving down the highway. As alluded to above, a 6 ft margin of error in heavy traffic on a major highway can result in tragedy.</p>



<p>However, there is a version of GPS that provides a finer grainer of detection. This version is the&nbsp;<a href="https://en.wikipedia.org/wiki/Differential_GPS">Differential Global Positioning System</a>&nbsp;(DGPS).</p>



<p>DGPS is a network of fixed ground-based reference stations that broadcast the difference between the location reported by the GPS satellite system and known fixed positions. These stations broadcast the difference between the&nbsp;<a href="https://www.sciencedirect.com/topics/engineering/pseudorange">pseudoranges</a>&nbsp;provided by the satellites orbiting the Earth and the actual, internally computed pseudoranges. Also, the receiver stations may correct their pseudoranges by the same amount. The digital correction signal is typically broadcast locally over a shorter-range version of ground-based transmitters. DGPS has a margin of error that ranges from 15 meters (49 ft), which is the high end of GPS accuracy, to about 1–3 centimeters (0.39–1.18 in) which is well below the 6 ft low-end range of GPS. Thus, in many cases, a DGPS receiver can detect an edge device with an accuracy of inches. This type of accuracy is very acceptable for making a pizza delivery to a room in a college dormitory. However, it’s still a risk when a self-driving vehicle travels a highway at high speed. Fortunately, when it comes to effective location detection for automobiles driving at high speeds, there is an alternative approach: sensors.</p>



<h2 class="wp-block-heading">Alternative Approach to Device Location</h2>



<p>Let’s revisit the above mentioned principle: a subject never knows its location. It needs some external objective reference mechanism to make the determination. Street signs, IP address lookup, and GPS/DGPS provide such a reference. Being told where you are is an important aspect of location detection. But there is another way to look at things. While a subject may not be able to determine where it is, it can determine what’s nearby and how far away external objects are. All it needs to do is look around. Hence the benefit of using an optical sensor. After all, what are your eyes if not an optical sensor?</p>



<p>Self-driving&nbsp;<a href="https://www.udacity.com/blog/2021/03/how-self-driving-cars-work-sensor-systems.html">cars use optical sensors</a>, as do&nbsp;<a href="https://www.vishay.com/docs/48708/ig18692481_vacuum_cleaner_robots.pdf">robotic vacuum cleaners</a>. You can&nbsp;<a href="https://play.google.com/store/apps/details?id=com.caramba.easymeasure&amp;hl=fr&amp;gl=US">add software</a>&nbsp;to your cellphone to enable distance determination utilizing the phone’s camera as the optical sensor.</p>



<p>Optical sensors become particularly important for automated IoT devices that need to work in close proximity to one another, for example, robotic forklifts in a warehouse.</p>



<p>Combining optical sensors with GPS/DGPS tracking can provide the level of detail required for highly accurate location detection of edge devices. You don’t need to know where you are in order to make that determination; all you need to know is how far away something else is. It’s an intriguing approach to location detection that’s still evolving.</p>



<h2 class="wp-block-heading">Putting It All Together</h2>



<p>Edge computing and edge devices will continue to grow as a presence both on the Internet and in the physical world.&nbsp;<a href="https://www.globenewswire.com/news-release/2022/03/03/2396216/0/en/Edge-Computing-Market-Size-Worth-61-14-Billion-by-2028-CAGR-38-4-Grand-View-Research-Inc.html">Grand View Research, Inc reports</a>&nbsp;that the edge computing market is expected to have a compound annual growth rate (CAGR) of 38.4% and reach a market size of $61.14 bn USB by 2028. These are not trivial numbers.</p>



<p>Many, if not most, of those edge devices will need to know where they are to do the work they’re intended to do. This means that location detection is not a “nice to have,” and it’s a mission-critical requirement. However, as described in this article, there’s a lot of variety in location detection techniques. It is important to understand what these techniques are, how they work, and how they’re best used. In some cases, it’s a matter of life and death. As you can see, there’s a lot to know, and the information provided here is a good starting point from which to grow your understanding.</p>



<p>A good many, if not most of those edge devices, will need to know where they are in order to do the work they’re intended to do. This means that location detection is not a “nice to have”. It’s a mission critical requirement. However, as described in this article, there’s a lot of variety in location detection techniques. Understanding what these techniques are, how they work and how they’re best used is important information to have. In some cases, it’s a matter of life and death. As you can see, there’s a lot to know. The information provided here is a good starting point from which to grow your understanding.</p>



<figure class="wp-block-image"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2022/07/lamp.png" alt=""/></figure>



<h2 class="wp-block-heading">Did you know:</h2>



<p>Powered by mimik’s edgeEngine, the Ad Hoc Service Mesh technology enable discovery, connection and communication among node (devices) that can belong to three types of clusters. The cluster types are called Network, Account and Proximity.</p>



<p><strong>Network cluster</strong>&nbsp;– nodes that are part of the same network.</p>



<p><strong>Account cluster</strong>&nbsp;– nodes that are part of the same user account.</p>



<p><strong>Proximity cluster</strong>&nbsp;– nodes that are close to one another in terms of physical geo-location.</p>



<p>Machines and devices in an Account and Proximity cluster can reside anywhere. Their association to one another is beyond the boundaries of a network.</p>



<p><a role="button" href="https://devdocs.mimik.com/key-concepts/06-index"><br>Learn More<br></a></p><p>The post <a href="https://mimik.com/a-primer-to-geolocation-detection-on-the-edge/">A primer to geolocation detection on the Edge</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Understanding the limits of replication and redundancy under edge architectures</title>
		<link>https://mimik.com/understanding-the-limits-of-replication-and-redundancy-under-edge-architectures/</link>
		
		<dc:creator><![CDATA[Bob Reselman]]></dc:creator>
		<pubDate>Tue, 08 Nov 2022 16:10:24 +0000</pubDate>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Bob Reselman]]></category>
		<guid isPermaLink="false">https://stg-2x.mimik.com/?p=77236</guid>

					<description><![CDATA[<p>Replication and redundancy have been key components of computing for a long time, since the heyday of the mainframe. Back then, if a mainframe lost power, everything stopped. Organizations addressed this risk by keeping generators and power supplies on hand to supply redundant electrical backups. If power from the main power grid failed, the generators took over. No electricity was lost.</p>
<p>The post <a href="https://mimik.com/understanding-the-limits-of-replication-and-redundancy-under-edge-architectures/">Understanding the limits of replication and redundancy under edge architectures</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></description>
										<content:encoded><![CDATA[<h2 class="wp-block-heading">Executive Summary</h2>



<ul>
<li>Edge computing and IoT-based distributed architectures differ from architectures based on orchestration frameworks targeted for implementation within a data center.</li>



<li>Edge computing and IoT architectures are intended for dedicated devices used over a wide geography.</li>



<li>As such, the redundancy and replications techniques used for systems hosted in data centers do not apply.</li>



<li>In order to address this difference, architects need to alter the way they think about redundancy and replication within the edge computing paradigm.</li>
</ul>



<p>Replication and redundancy have been key components of computing for a long time, since the heyday of the mainframe. Back then, if a mainframe lost power, everything stopped. Organizations addressed this risk by keeping generators and power supplies on hand to supply redundant electrical backups. If power from the main power grid failed, the generators took over. No electricity was lost.</p>



<p>Mainframes also store data exclusively on or within the machine. Thus, if the storage mechanism failed, data was lost. So companies backed up the data to tape and this was an early form of data replication.</p>



<p>When personal computers first appeared, they, too,&nbsp; used the same redundancy and replication techniques used for mainframes. A user had an uninterrupted power supply close by in case of power failure. Data was replicated to tape or floppy drive.</p>



<p>Things changed when networking PCs together made distributed computing possible. This was particularly telling in database technology. Companies networked a number of computers together. One computer hosted the database server. Other computers acted as file servers that stored the data the database used.</p>



<p>Eventually, database technology matured to the point where the database was smart enough to replicate data among a variety of machines. Database technology progressed even further. Multiple databases that had the same processing logic were placed behind a load balancer – a traffic cop, if you will. The load balancer routed incoming traffic among the various redundant database servers. This redundancy avoided overloading the system.</p>



<p>Redundancy and replication have withstood the test of time. Both are used extensively today, most noticeably with applications that are hosted in a data center and accessed over the internet. Yet, as popular as replication and redundancy are, they are not without limits. These limitations become particularly apparent when working with edge computing and the Internet of Things.</p>



<p>Distributed systems at the edge are not the same as distributed systems that are hosted within a data center. Edge computing is a new approach to machine distribution that requires new thinking. This difference requires those designing distributed applications for edge computing to reconceptualize replication and redundancy.</p>



<p>The purpose of this article is to examine new ways to think about replication and redundancy as it relates to distributed edge computing. The place to start is to understand the essential difference between the traditional approach to distributed computing, which focuses on the data center, and distributed computing on edge devices and the Internet of Things.</p>



<h2 class="wp-block-heading">Typical redundancy is a distributed system in a data center</h2>



<p>A typical approach to distributed computing is to use a pattern in which replicas of a particular algorithm are represented by a service layer. Then, the service becomes one of many other services represented by different algorithms that are accessed via some sort of gateway mechanism. Each service has load balancing capabilities that ensures that no one instance of its underlying algorithms are overloaded. (See Figure 1.)</p>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2022/11/Picture1.png" alt=""/></figure></div>


<p><b>Figure 1: A typical pattern in distributed architecture in which redundancy ensures availability and efficient performance</b></p>



<p>Kubernetes uses this type of distribution pattern, as does Docker Swarm.</p>



<p>The benefit of this pattern is that using redundant algorithms ensures resilience. If one of the instances goes down, other identical instances of the algorithm are still available to provide computing logic. And, if automatic replication is in force, when an instance goes down, the replication mechanisms can try to resurrect it. If the instance can’t be reinstated, the replication mechanism will create a new one to take its place. Replication of this type is used by Kubernetes with its Deployment resource.</p>



<p>As powerful as this type of architecture is, it’s not magical. A lot of work needs to go into getting and keeping an architecture of this type up and running. First and foremost, the various components that make up the system need to know a good deal about each other. At the logical level, a service needs to know about its algorithms, and the gateway mechanism needs to know about the services it’s supporting. At the physical level, service and algorithms reside on separate machines; therefore, access between and among machines needs to be granted accordingly. This can become an arduous task. Imagine an architecture as the one shown below in Figure 2. The service lives on one machine, and each instance and its algorithms live on a distinct machine. Should one machine go down, then another one needs to replace it. In the old days, this meant that someone actually had to go down to a data center and physically install the machine and then add it to the network.</p>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2022/11/Picture2.png" alt=""/></figure></div>


<p><b>Figure 2: Replication can be very hard to support at the hardware level, particularly when a new machine needs to be added to the system.</b></p>



<p>Of course, modern distributed technologies have evolved to the point where machine replacement means nothing more than spinning up a virtual machine on a host computer and then adding that VM to the network. However, while automation will do the work, the laws of time and space still exist. It takes time to spin up the VM, and that new VM needs to be added to the network and made available to the application.Fortunately, orchestration technologies for Linux containers, most notably Kubernetes, have significantly reduced the risk of large-scale failure, even at the hardware level. However, while this type of pattern works well within the physical confines of a data center or among many data centers, systems that rely on redundancy and replication experience significant limitations when it comes to edge computing.</p>



<h2 class="wp-block-heading">The limits of redundancy and replication in edge architecture</h2>



<p>The essential idea of edge computing is that a remote device has the ability to execute predefined computational logic and also communicate to other devices to do work. One of the more common examples of edge computing is the red-light traffic camera.</p>



<p>A municipality places a camera at a traffic intersection controlled by a red-light. When a motor vehicle runs a red light, the camera has the intelligence to detect the violation and take a photo of the offender. Also, the device is able to send to another computer that acts as a data collector the photo of the offending vehicle along with some metadata describing the time of the violation. The collector can either process the photo and metadata on its own or pass it all on to other intelligence that can do the analysis. (See Figure 3, below.)</p>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2022/11/Picture3.png" alt=""/></figure></div>


<p><b>Figure 3: Red-light traffic cameras are a commonplace example of edge computing.</b></p>



<p>What distinguishes the red-light traffic camera as an edge device is that it has intelligence. Unlike a closed circuit television system in which the camera does nothing more than transmit an ongoing video signal back to a television monitor in another location, a red-light traffic camera understands some of what it sees to make law enforcement decisions. There is no human evaluating the video transmission. Computational intelligence does it all. Cameras are distributed above the city, and each camera has the ability to communicate back to a central collector. Thus, you can think of red-light camera systems as distributed architecture.</p>



<p>But, while a red-light camera system is indeed a type of distributed architecture, it does have a significant shortcoming. Such a system is incapable of supporting automated redundancy and replication.</p>



<p>Think about it.</p>



<p>Should the red-light camera on the corner of Main St. and 6th Ave go offline, that capability for monitoring traffic goes away too. No red-light violations will be reported by that device until a technician goes out into the field and repairs the camera.</p>



<p>So then, given the inherent limitation of this type of distributed architecture, how do we create traffic camera systems that have redundancy built in? The easiest solution is to put a number of traffic cameras at each interaction but make only one operational. If the operational camera goes offline, intelligence back on the controller will take notice that the first camera is not working and turn on the backup to take its place. (See Figure 4.)</p>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2022/11/Picture4.png" alt=""/></figure></div>


<p><b>Figure 4: Edge devices in the real world require real world redundancy.</b></p>



<p>Having backup devices on hand is a typical way of doing redundancy in the real world. Hospitals are designed with generators that provide electricity in the event of a power failure from the public grid. Practically all industrial-strength&nbsp;<a href="https://www.cat.com/en_US/by-industry/electric-power/electric-power-industries/data-centers.html" target="_blank" rel="noopener">data centers use backup power generators</a>&nbsp;too.</p>



<p>The notion of physical backup is not confined to electricity only. Professional rock bands always travel with an extra set of amplifiers to ensure that if an amplifier malfunctions on stage, a replacement is readily available to plugin. Guitarists usually have a backup guitar on hand in case a string breaks. As they say, the show must go on even in the world of edge computing.</p>



<h2 class="wp-block-heading">Edge computing vs the data center</h2>



<p>The most important thing to understand about edge architectures is that they are different from architectures that are intended for devices in a data center.</p>



<p>These days most devices in a data center are virtualized in terms of computing resources and networking. Thus, they can be replenished easily using automation because of their virtual nature. Kubernetes can easily redirect traffic away from a failing piece of hardware. And, if the alternative hardware becomes overworked, modern provisioning software can automatically detect available hardware and spin up a new VM accordingly. Then Kubernetes can take over and create the virtual assets needed to keep things going.</p>



<p>Of course, things can go very wrong quickly when a data center goes offline or a network wire gets cut by accident. However, while these cases can be catastrophic, they are rare. More often than not, failures occur among virtual devices.</p>



<p>On the other hand, edge devices are real, not virtual, and a whole class of edge devices is mobile, for example, robots, tractors, forklifts, and delivery trucks. Thus, the techniques that are usual for data center replication do not apply. Replication is very much about the physical device and the geography in which it operates. For example, how do you replicate intelligence in a cell phone performing some mission-critical operation on an oil rig in the middle of the North Sea? How do you provide redundancy for a&nbsp;<a href="https://techhq.com/2022/01/robot-tractors-among-automation-storming-us-farms-in-2022/" target="_blank" rel="noopener">robotic tractor</a>&nbsp;tilling an irrigated field in a remote area of Sub-Saharan Africa? Even at a consumer level, the Internet-enabled refrigerator in my house is in my house! If it fails, I can only go across the street and use my neighbor&#8217;s if I have very generous neighbors.</p>



<p>The essential question becomes, how does a company implement redundancy and replication in edge architecture?</p>



<p>When designing edge architecture and architectures for IoT, it is essential to remember that these devices exist as physical entities in the world and need to be accommodated as such. There is no virtual magic to be had. If you want to build redundancy into your edge architecture, as shown in the red-light traffic camera example above, it needs to be done on the physical plane.</p>



<p>You need to plan for backup devices that are readily available in terms of time and real space. This means having physical backups on hand, whether the device is a cell phone or forklift. Yes, this approach is a bit old school, but nonetheless, the solution is valid. Bringing one-size-fits-all virtualization thinking to real assets in the real world won&#8217;t work. When it comes to edge architectures, the devil is in the device. The takeaway is simple: have a physical backup on hand.</p>



<figure class="wp-block-image"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2022/07/lamp.png" alt=""/></figure>



<h2 class="wp-block-heading">Did you know:</h2>



<p>Did you know that the hybrid edgeCloud provides the opportunity to take advantage of collaboration and resource sharing across devices?</p>



<p><a href="/hybrid-edge-cloud-a-pragmatic-approach-for-decentralized-cloud-computing/" target="_blank" rel="noopener">Download the IEEE Article: &#8220;Hybrid Edge Cloud: A Pragmatic Approach for Decentralized Cloud Computing&#8221;</a></p>



<p><a role="button" href="https://mimik.com/hybrid-edge-cloud-a-pragmatic-approach-for-decentralized-cloud-computing/"><br>Download<br></a></p><p>The post <a href="https://mimik.com/understanding-the-limits-of-replication-and-redundancy-under-edge-architectures/">Understanding the limits of replication and redundancy under edge architectures</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Understanding the limitations of using Kubernetes at the edge</title>
		<link>https://mimik.com/understanding-the-limitations-of-using-kubernetes-at-the-edge/</link>
		
		<dc:creator><![CDATA[Bob Reselman]]></dc:creator>
		<pubDate>Wed, 12 Oct 2022 04:29:22 +0000</pubDate>
				<category><![CDATA[Blog]]></category>
		<category><![CDATA[Bob Reselman]]></category>
		<guid isPermaLink="false">https://stg-2x.mimik.com/?p=77038</guid>

					<description><![CDATA[<p>Kubernetes is essentially an orchestration framework for Linux containers. Getting a Linux container to run on a cell phone is hard, really hard.</p>
<p>The post <a href="https://mimik.com/understanding-the-limitations-of-using-kubernetes-at-the-edge/">Understanding the limitations of using Kubernetes at the edge</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></description>
										<content:encoded><![CDATA[<p>Want to have some fun over the weekend? Try creating a Kubernetes cluster using cell phones as a farm of&nbsp;worker nodes. It’s not fun. I know. I’ve tried it.</p>



<p>Kubernetes is essentially an orchestration framework for Linux containers. Getting a Linux container to run on&nbsp;a cell phone is hard, really hard. All the tools and capabilities that developers enjoy when working with a full&nbsp;installation of Linux on a X86 or even a Raspberry Pi computer are luxuries when working with a cell phone’s&nbsp;operating system. While it’s true that both the iOS and Android operating systems are derivatives of Linux, the&nbsp;stuff you need in order to run Linux containers is missing on a cell phone. Getting something as commonplace&nbsp;as an nginx container up and running on an iPhone is akin to rocket science even for someone who&nbsp;understands the details of Kubernetes. For a beginner, fuhgeddaboudit.</p>



<p>Thus, no containers, no Kubernetes. It’s that simple. Wish it was easy, but it’s not. Still understanding why&nbsp;running Kubernetes on cell phones is so hard is useful information, particularly for those of us, myself included,&nbsp;who harbor such fantasies. As they say, the devil is always in the details and when it comes to running&nbsp;Kubernetes on cell phones the details count. So, let’s look at them.</p>



<p>The place to start is understanding how containers run on a Linux computer.</p>



<h2 class="wp-block-heading">Containers are isolated Linux processes</h2>



<p>The most important thing to understand is that containers do not run under a container manager such as&nbsp;Docker or Podman. Rather, containers run as independent Linux processes that are virtually isolated from&nbsp;other processes. The container manager is a helper toward that end.</p>



<p>Container isolation is created using features available in the Linux kernel. Thus, you can think of a Linux&nbsp;container as an isolated process that runs on top of the Linux kernel. (See Figure 1, below.)</p>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2022/10/img1.png" alt=""/></figure></div>


<p><b>Figure 1: A container a Linux process that runs in virtual isolation over the Linux kernel</b></p>



<p>The Linux kernel on which a container runs can be hosted on a virtual machine or on bare metal. The&nbsp;component that does the work of creating and isolating a container process is called the container runtime.&nbsp;Examples of a container runtime are&nbsp;<a style="background-color: #ffffff; font-size: 1rem;" href="https://containerd.io/" target="_blank" rel="noopener">containerD</a>,&nbsp;<a style="background-color: #ffffff; font-size: 1rem;" href="https://www.docker.com/blog/runc/" target="_blank" rel="noopener">runC&nbsp;</a>and&nbsp;<a style="background-color: #ffffff; font-size: 1rem;" href="https://www.redhat.com/en/topics/containers/what-is-rkt" target="_blank" rel="noopener">rkt</a>. The role of a container manager such as&nbsp;Docker is to present a way for humans or machines to work with the container runtime.&nbsp;Let’s take a look at the work the container runtime does in order to create a container</p>



<h2 class="wp-block-heading">Creating a container</h2>



<p>As mentioned above, the role of the container runtime is to create and manage the lifecycle of a container. When a container manager such as Docker contacts the container runtime – containerD, for example – to create a container. Then the container runtime will do four things.</p>



<p>First the container runtime&nbsp; will create the container’s Linux process.</p>



<p>Second, it will dedicate the Linux process to a custom&nbsp;<a href="https://en.wikipedia.org/wiki/Linux_namespaces" target="_blank" rel="noopener">Linux namespace</a>. According to the Linux manual, a namespace wraps a global system resource in an abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource. Dedicating a process to a namespace creates the essential isolation that a container requires.</p>



<p>After the container runtime creates the namespace it then assigns&nbsp;<a href="https://en.wikipedia.org/wiki/Cgroups" target="_blank" rel="noopener">cgroups&nbsp;</a>(control groups) to the process. A cgroup defines how a particular process can use system resources. For example you can use cgroups to limit how much memory or CPU a process can use as well as assign network and disk access priority.</p>



<p>Finally, the container runtime creates an&nbsp;<a href="https://www.kernel.org/doc/html/latest/filesystems/overlayfs.html" target="_blank" rel="noopener">overlay filesystem</a>&nbsp;for the container. The overlay filesystem creates a special layer on the host filesystem that makes it seem as if the container has its own files, even at the OS level. (See Figure 2, below)</p>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2022/10/img2.png" alt=""/></figure></div>


<p><b>Figure 2: The container creation process executed by the container runtime</b></p>



<p>In short, as shown in Figure 3 below, give a Linux process a namespace, assign it to cgroups and an overlay filesystem and you end up with a Linux container. (See Figure 3 below.)</p>


<div class="wp-block-image">
<figure class="aligncenter"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2022/10/img3.png" alt=""/></figure></div>


<p><b>Figure 3: Linux containers combine Linux kernel features around a Linux process</b></p>



<p>Now, while the container creation process seems pretty straightforward at the conceptual level, when it comes to actually making containers, it’s a lot of hard work on the part of the container runtime that gets executed in milliseconds.</p>



<p>As current events have revealed, Linux containers have caught on like wildfire. Also, today they’re the cornerstone of the container orchestration technology Kubernetes, which, by the way, has also caught on line wildfire.</p>



<p>But as powerful as containers and their descendant Kubernetes pods are, they are not a one-size-fits-all solution, particularly when it comes to distributed IoT architectures that use mobile phones and tablets.</p>



<p>The challenges to get containers running on a cell phone are anything but trivial. There are some significant hurdles to overcome</p>



<h2 class="wp-block-heading">The hurdles to overcome</h2>



<p>The first hurdle that needs to be overcome to get a container up and running on a cell phone is that you need to be able to install a container manager and container runtime on the device. Taking the simplest approach, this means that you have to SSH into the phone and download the release files for the container manager and runtime , which are probably in a compressed format. Then you have to install them.</p>



<p>This might be a simple enough task if you had a terminal prompt to work with. But, out of the box on a cell phone, you don’t. So you have to install a terminal app from an app store.</p>



<p>Then, once you get the terminal up and running there’s no guarantee that your phone will have all the utilities that you need. There’s no wget or curl. There’s probably no zip or tar utilities installed to extract the container manager and container runtime from the downloads.</p>



<p>You’ll have to do a lot of work just to get the files. And, once you have the container manager and container runtime on the cell phone, there’s no guarantee they’ll work. Remember, containers rely upon a lot of low-level features in the Linux kernel. They might be there; they might not.</p>



<p>Now, let’s say by some miracle you do get a container to load in your cell phone. You still have a long way to go to actually turn it into a worker node that can be part of a Kubernetes cluster. That’s another bucket of work that’s just as detailed and fraught with potential errors. Kubernetes has more moving parts than containers. If any one of those parts fails to work as expected, you’re in for some hurt.</p>



<p>In short, get containers and Kubneretes to run on a cell phone is a crapshoot; a time consuming, labor intensive crap shoot with little, if any guarantee of success</p>



<h2 class="wp-block-heading">Addressing the issue</h2>



<p>So, then what’s to be done?</p>



<p>In terms of getting Linux containers to run on a cell phone or mobile tablet, the question to ask is: why?</p>



<p>Containers in general and Kuberenetes in particular have their origins in the datacenter. Containers came about as a way to increase the efficiency of process isolation beyond the capabilities of virtual machines. Containers load very fast, on the order of milliseconds. Loading a VM can take minutes.</p>



<p>Also, the ecosystem for distributing a container is built around the Container Image Repository of which DockerHub is the most familiar. The container image is the template that describes the parts necessary to create a container at runtime. If the container image exists on the local machine the container manager will use the local copy. If not, the container manager is smart enough to figure out how to get the required container image from a repository on the internet.</p>



<p>Cell phones and mobile tablets on the other hand use the app store model. When you want to add an app to your cell phone you go to the Apple App Store or Google Play and intentionally download the app. It’s not a process that lends easily to the type of automation that’s used in a data center. The app store pattern is essentially focused on human instigation</p>



<p>On the other hand, the app store pattern is a lot easier to use than the container image repository pattern. The app store pattern is a click and download process. This is its virtue. It’s a hard process that’s hard to break. Container automation is a lot more fragile.</p>



<p>The long and short of it is that if you’re looking to make mobile devices such as cell phones or tablets part of distributed architecture, make sure they’re being used in a way that makes sense. For example, there’s a good case to be made that a cell phone can be a valuable contributor to a larger distributed system by providing locale based face recognition capability. But, to expect that cell phone to provide that capability as part of a Kubernetes cluster doesn’t really make sense when you consider the time and labor required to make it happen.</p>



<p>An alternative approach is to devise a distributed architecture that’s compatible with the mobile computing ecosystem, particularly around distributing applications and components.</p>



<p>As they say, when in Rome, do as the Romans do. The analogy rings true when thinking about creating distributed architectures that use mobile devices. Or, if you have the time, tolerance and expertise, you can devote a weekend of your life and try to get a Linux container to run on a cell phone. If you’ve had both pleasure and success making it all happen, by all means, please let me know. This is a case where I’d love to be proven wrong.</p>



<figure class="wp-block-image"><img decoding="async" src="https://stg-2x.mimik.com/wp-content/uploads/2022/07/lamp.png" alt=""/></figure>



<h2 class="wp-block-heading">Did you know:</h2>



<p>Did you know that In environments that cannot run container daemons (e.g., smartphones), mimik’s edgeEngine provide additional “light” container capabilities with the ability to download, deploy, and operate microservices ?</p>



<p><a role="button" href="https://devdocs.mimik.com/key-concepts/01-index"><br>Learn about Fundamentals of mimik edgeEgine Runtime<br></a></p><p>The post <a href="https://mimik.com/understanding-the-limitations-of-using-kubernetes-at-the-edge/">Understanding the limitations of using Kubernetes at the edge</a> first appeared on <a href="https://mimik.com">mimik Technology Inc</a>.</p>]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
